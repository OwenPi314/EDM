{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "from scipy.fft import rfft\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The raw training/validation/test data are the paths to the audio files, labels for now are just the emotions. The gender and intensity lists maybe further used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = []\n",
    "raw_val_data = []\n",
    "raw_test_data = []\n",
    "\n",
    "train_label = []\n",
    "val_label = []\n",
    "test_label = []\n",
    "\n",
    "train_gender = []\n",
    "val_gender = []\n",
    "test_gender = []\n",
    "\n",
    "train_intensity = []\n",
    "val_intensity = []\n",
    "test_intensity = []\n",
    "\n",
    "for i in range(0, 16):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "    \n",
    "    for ele in inputs:\n",
    "        raw_train_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        train_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        train_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        train_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)\n",
    "    \n",
    "for i in range(16, 20):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "\n",
    "    for ele in inputs:\n",
    "        raw_val_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        val_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        val_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        val_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)\n",
    "        \n",
    "for i in range(20, 24):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "\n",
    "    for ele in inputs:\n",
    "        raw_test_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        test_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        test_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        test_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use librosa to load the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_train_data = []\n",
    "for ele in raw_train_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_train_data.append(np.pad(temp, (0, 116247 - len(temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_val_data = []\n",
    "for ele in raw_val_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_val_data.append(np.pad(temp, (0, 116247 - len(temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_test_data = []\n",
    "for ele in raw_test_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_test_data.append(np.pad(temp, (0, 116247 - len(temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad([1,2,3], (0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Fourier transform of the data as features\n",
    "The result of from the Fourier transform on the entire data set may not offer much information since all information about time in the sound is inherently lost. In human speech, having a high pitch at the beginning may indicate very different emotions from having a high pitch at the end. I do not expect great results from such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_train_data = []\n",
    "for ele in lbr_train_data:\n",
    "    temp = rfft(ele)\n",
    "    fft_train_data.append(temp.real)\n",
    "        \n",
    "fft_val_data = []\n",
    "for ele in lbr_val_data:\n",
    "    temp = rfft(ele)\n",
    "    fft_val_data.append(temp.real)\n",
    "        \n",
    "fft_test_data = []\n",
    "for ele in lbr_test_data:\n",
    "    temp = rfft(ele)\n",
    "    fft_test_data.append(temp.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using KNN classifier for FFT features\n",
    "As seen here, FFT+KNN yields validation errors slightly better than chance, I would expect similar results for the test error, therefore, I did not evaluate based on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=30)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the knn classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 30)\n",
    "knn_classifier.fit(fft_train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14166666666666666"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizing the knn classifier\n",
    "knn_classifier.score(fft_val_data, val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results from testing with different number of neighbors for FFT features\n",
    "n = 1: 0.1167  \n",
    "n = 3: 0.1167  \n",
    "n = 5: 0.125  \n",
    "n = 10: 0.1   \n",
    "n = 15: 0.125  \n",
    "n = 20: 0.1083  \n",
    "n = 25: 0.1208  \n",
    "n = 30: 0.1417  \n",
    "n = 35: 0.1333  \n",
    "n = 40: 0.1333  \n",
    "n = 50: 0.1333  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get spectrograms of the audio input as features as to preserve the time dimension of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_train_data = []\n",
    "for ele in lbr_train_data:\n",
    "    temp = librosa.stft(ele, n_fft = 512)\n",
    "    stft_train_data.append(temp.real.reshape(-1))\n",
    "        \n",
    "stft_val_data = []\n",
    "for ele in lbr_val_data:\n",
    "    temp = librosa.stft(ele, n_fft = 512)\n",
    "    stft_val_data.append(temp.real.reshape(-1))\n",
    "        \n",
    "stft_test_data = []\n",
    "for ele in lbr_test_data:\n",
    "    temp = librosa.stft(ele, n_fft = 512)\n",
    "    stft_test_data.append(temp.real.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using KNN with spectrogram as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=30)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the knn classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 30)\n",
    "knn_classifier.fit(stft_train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [1,3,5,10,15,20,30,40,50]:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn_classifier.fit(stft_train_data, train_label)\n",
    "    print(str(n) + \":\" + str(knn_classifier.score(stft_val_data, val_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 1:  \n",
    "n = 3  \n",
    "n = 5  \n",
    "n = 10  \n",
    "n = 15  \n",
    "n = 20  \n",
    "n = 30  \n",
    "n = 40  \n",
    "n = 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
