{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The raw training/validation/test data are the paths to the audio files, labels for now are just the emotions. The gender and intensity lists maybe further used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = []\n",
    "raw_val_data = []\n",
    "raw_test_data = []\n",
    "\n",
    "train_label = []\n",
    "val_label = []\n",
    "test_label = []\n",
    "\n",
    "train_gender = []\n",
    "val_gender = []\n",
    "test_gender = []\n",
    "\n",
    "train_intensity = []\n",
    "val_intensity = []\n",
    "test_intensity = []\n",
    "\n",
    "for i in range(0, 16):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "    \n",
    "    for ele in inputs:\n",
    "        raw_train_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        train_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        train_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        train_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)\n",
    "    \n",
    "for i in range(16, 20):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "\n",
    "    for ele in inputs:\n",
    "        raw_val_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        val_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        val_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        val_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)\n",
    "        \n",
    "for i in range(20, 24):\n",
    "    # Get all file names in the dir\n",
    "    actor = \"Actor_%02d\" % (i + 1)\n",
    "    inputs = os.listdir('./data/RAV/' + actor)\n",
    "\n",
    "    for ele in inputs:\n",
    "        raw_test_data.append('./data/RAV/' + actor + '/' + ele) # Form paths to the files\n",
    "        \n",
    "        file_name = ele.split('-')\n",
    "        test_label.append(int(file_name[2]))                    # Get emotion label\n",
    "        test_intensity.append(int(file_name[3]))                # Get intensity\n",
    "        test_gender.append((i + 1) % 2)                         # Get gender (1 for male, 0 for female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use librosa to load the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_train_data = []\n",
    "for ele in raw_train_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_train_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_val_data = []\n",
    "for ele in raw_val_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_val_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbr_test_data = []\n",
    "for ele in raw_test_data:\n",
    "    temp, _ = librosa.load(ele)\n",
    "    lbr_test_data.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Fourier transform of the data as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_train_data = []\n",
    "for ele in lbr_train_data:\n",
    "    temp = fft(ele, n = 116247)\n",
    "    fft_train_data.append(temp)\n",
    "        \n",
    "fft_val_data = []\n",
    "for ele in lbr_val_data:\n",
    "    temp = fft(ele, n = 116247)\n",
    "    fft_val_data.append(temp)\n",
    "        \n",
    "fft_test_data = []\n",
    "for ele in lbr_test_data:\n",
    "    temp = fft(ele, n = 116247)\n",
    "    fft_test_data.append(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
